{"cells":[{"cell_type":"markdown","metadata":{"id":"5DYJwNdGOrc-"},"source":["# IACV Exercise 5: Transfer Learning\n","\n","**Deadline: 23 December 2022, 11:59 PM**  \n","**Covered Topics: Lecture 9-10**\n","\n","In this exercise, you will again tackle the image classification task, as in exercise 4. Given an input RGB image with resolution `(32, 32, 3)`, you need to predict which of the 10 input classes it belongs to. However, unlike in exercise 4, you have access to limited training data in `training.h5`. In fact, you only have `210` samples per class, which are separated into training, validation, and test sets of ratio `7:1:2` for ease of use. You can use these three sets of data for your development.\n","\n","**Note that the real test data you should evaluate your model has `1000` images without labels and can be found in `test.h5`.** \n","\n","Fortunately, you have access to a pre-trained network which has been trained on large amounts of data to classify 5 out of 10 input classes. That is, the pre-trained network obtains a classification accuracy of around 95% for 5 of the classes, while the remaining classes are not defined at all. Its parameters are defined in `resnet4five.pt` and the loading process explained in **Load pre-trained model** below.\n","\n","Your task is to either adapt this model, or train a new network from scratch which can classify all 10 classes.\n","\n","**Note:** Similar to exercise 4, we will use the [PyTorch](https://https://pytorch.org/) deep learning framework in this exercise. Thus we highly recommend going through exercise 4 first before starting with this exercise.\n","\n","**Evaluation Criteria**\n","\n","Your algorithm will be evaluated using classification accuracy, which is the proportion of images with the correct predicted label.\n","The final EvaluationScore is obtained as the classification accuracy over all test samples, over all 10 classes.\n","\n","**Passing requirement**\n","\n","Your algorithm will be evaluated on a test set. In order to pass the exercise, you need to obtain an EvaluationScore of **greater than $60.0$** on the test set.\n","\n","Follow the steps in the rest of the notebook to generate the submission. The evaluation server for the exercise is at https://codalab.lisn.upsaclay.fr/competitions/9001. The notebook also contains an additional tutorial on some deep learning operations with PyTorch, which you may find useful to complete the exercise.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PwCTa9CLPHYb"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/bv/3kttr09s6dsg653szk2tbhlh0000gn/T/ipykernel_26272/3060181211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mpy_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mnative_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# These two lines ensure that we always import the latest version of a package, \n","# in case it has been modified.\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","import csv\n","import cv2\n","import os\n","import numpy as np\n","import random\n","import shutil\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","import sys\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w157_tWbPUhU"},"outputs":[],"source":["iacv_path = '.'\n","\n","env_path = f'{iacv_path}'\n","# Add the handout folder to python paths\n","if env_path not in sys.path:\n","    sys.path.append(env_path)\n","\n","# Create folder to store checkpoints\n","os.makedirs(f\"{env_path}/ckpt\", exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"AIZmtynK8aY0"},"source":["Define a mapping from 5 to 10 classes because the indices do not match, such as `classes[0]` is `Airplane` while `classes5[0]` is `Cat`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tj7vLLTsImlM"},"outputs":[],"source":["# Mapping from 5 to 10 classes\n","\n","# Classes for the pretrained dataset\n","classes5 = [\"Cat\", \"Deer\", \"Frog\", \"Ship\", \"Truck\"]\n","\n","# Actual classes\n","classes = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \n","           \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","\n","# Converting numpy arrays for indexing\n","classes5 = np.array(classes5)\n","classes = np.array(classes)\n","\n","# Mapping from 5 classes to 10 classes for evaluation\n","map5to10 = [np.where(classes==class_)[0][0] for class_ in classes5]\n","map5to10 = np.array(map5to10)\n","print(\"Mapping array is:\", map5to10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFEMjFFL-AOQ"},"outputs":[],"source":["# Example usage\n","\n","# Random predictions by 5\n","preds5 = np.random.randint(5, size=7, dtype=int)\n","\n","# Predicted classes\n","print(\"Actual Predictions:        \", classes5[preds5])\n","\n","# Wrong mapping from 5 to 10 classes\n","print(\"Wrongly-mapped Predictions:\", classes[preds5])\n","\n","# Correct mapping from 5 to 10 classes\n","print(\"Correct-mapped Predictions:\", classes[map5to10[preds5]])"]},{"cell_type":"markdown","metadata":{"id":"xZZ7Pi3VRgBw"},"source":["Define the plotting functions to visualize the images and predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49cumfWBRfT7"},"outputs":[],"source":["# class labels. This provides the mapping from the integer label for \n","# an image to a descriptive name\n","\n","# function to show image\n","def show_images(ims, gt_labels, pred_labels=None):\n","    fig, ax = plt.subplots(1, len(ims), figsize=(12, 12))\n","    for id in range(len(ims)):\n","        im = ims[id]\n","        im = im / 2 + 0.5     # unnormalize\n","        im_np = im.numpy()\n","\n","        ax[id].imshow(np.transpose(im_np, (1, 2, 0)))\n","\n","        if pred_labels is None:\n","            im_title = f'GT: {classes[gt_labels[id]]}'\n","        else:\n","            im_title = f'GT: {classes[gt_labels[id]]}  '\n","            im_title += f' Pred: {classes[pred_labels[id]]}'\n","        ax[id].set_title(im_title)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"w2LFx6yAPZoI"},"source":["## Load pre-trained model\n","\n","As mentioned before, you have access to parameters of a pre-trained model `resnet4five.pt`, which is a standard ResNet18 model and has been trained to classify images into 5 classes (\"Cat\", \"Deer\", \"Frog\", \"Ship\", \"Truck\"), using larger dataset. It achieves accuracy of higher than 90% for these classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z4r22MAOrdC"},"outputs":[],"source":["from dataset import get_datasets_from_h5, get_loaders_from_datasets\n","\n","# Get the datasets\n","dataset_path = f'{env_path}/training.h5'\n","\n","train_dataset, val_dataset, test_dataset = get_datasets_from_h5(dataset_path)\n","\n","# Construct the dataloaders\n","batch_size = 24     # Feel free to change this\n","train_loader, val_loader, test_loader = \\\n","    get_loaders_from_datasets(train_dataset, val_dataset, test_dataset, \n","                              batch_size)\n","\n","# Create the model and summarize\n","num_classes = train_dataset.num_classes\n","input_size = train_dataset.image_size\n","\n","# Print the sizes of the datasets\n","print(f\"The dataset contains {train_dataset.num_classes} classes.\")\n","print(f\"Number of images in each dataset: Training={len(train_dataset)}, \", \n","      f\"Validation={len(val_dataset)}, Test={len(test_dataset)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"23Ihu991RwDg"},"source":["Visualize a few training samples along with the ground truth labels to get an idea of how the images look. You can run this multiple times to check different images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1PrWX3TSAWe"},"outputs":[],"source":["# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","# print(labels)\n","show_images(images[:6], labels[:6])"]},{"cell_type":"markdown","metadata":{"id":"cukc9chqOrdD"},"source":["## Load pre-trained model\n","\n","As mentioned before, you have access to parameters of a pre-trained model `resnet4five.pt`, which is a standard ResNet18 model and has been trained to classify images into 5 classes (\"Cat\", \"Deer\", \"Frog\", \"Ship\", \"Truck\"), using larger dataset. It achieves accuracy of higher than 90% for these classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sm2uH5G0Tk3q"},"outputs":[],"source":["import torch\n","from model import generate_resnet\n","\n","load_path = f'{env_path}/resnet4five.pt'     # Path to load the model from\n","\n","device = \"cpu\" # Device to train on\n","\n","# Create the model and summarize it. Note that the model has been trained to\n","# classify only 5 classes\n","num_classes = 5\n","model = generate_resnet(num_classes=num_classes) # Generate the resnet18 model\n","\n","# Next we load the pre-trained weights, and set it to the model we created\n","model.load_state_dict(torch.load(load_path, map_location=torch.device('cpu')))"]},{"cell_type":"markdown","metadata":{"id":"7n8VFaxYUa2T"},"source":["Next, we can test the pre-trained model on the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1zWLG_0OrdE"},"outputs":[],"source":["from evaluation import evaluate_model\n","\n","# Evaluate the model\n","val_accuracy = evaluate_model(model, val_loader, device=device, \n","                              mapping=map5to10)\n","print(f\"Validation accuracy with pretrained model: {val_accuracy:.3f}\")\n","test_accuracy = evaluate_model(model, test_loader, device=device, \n","                               mapping=map5to10)\n","print(f\"Test accuracy with pretrained model: {test_accuracy:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"B4ENgEef__2g"},"source":["To further analyse the performance, we will look at the the classification accuracy per-class.\n","\n","Define a plotting function for per-class accuracies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfUGqLA0Wz1L"},"outputs":[],"source":["# show class-based accuracies\n","\n","def show_class_accs(accs_dict, class_names=None, title=\" \"):\n","\n","    accs, names = list(), list()\n","    for key, value in accs_dict.items():\n","        name = class_names[key] if class_names is not None else str(key)\n","        names.append(name)\n","        accs.append(value)\n","\n","    y_pos = np.arange(len(names))\n","\n","    fig, ax = plt.subplots()\n","\n","    hbars = ax.barh(y_pos, accs, align='center')\n","    ax.set_yticks(y_pos)\n","    ax.set_yticklabels(names)\n","    ax.invert_yaxis()  # labels read top-to-bottom\n","    ax.set_xlabel('Accuracy')\n","    ax.set_title(title)\n","\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"embt7cfNWEyu"},"outputs":[],"source":["from evaluation import evaluate_model\n","\n","# Classwise Accuracies\n","val_class_accs = evaluate_model(model, val_loader, device=device, \n","                              mapping=map5to10, classwise=True)\n","\n","show_class_accs(val_class_accs, classes, title=\"Validation\")\n","\n","test_class_accs = evaluate_model(model, test_loader, device=device, \n","                               mapping=map5to10, classwise=True)\n","\n","show_class_accs(val_class_accs, classes, title=\"Test\")"]},{"cell_type":"markdown","metadata":{"id":"xz4VjaxmWse6"},"source":["As expected, we see the the pre-trained model obtains good performance on the 5 out of 10 classes which it has been trained for. However, it cannot handle the other 5 *unseen* classes, and thus obtains a low overall classification accuracy. Your task is to adapt this pre-trained model such that it obtains better overall classification accuracy, i.e. > 60%."]},{"cell_type":"markdown","metadata":{"id":"EgqqlhG3OrdF"},"source":["## Rules and Submission\n","\n","Throughout this project, you are **not allowed to use any other dataset and/or pre-trained model other than the given ones**. You are allowed to use any other techniques you have learned in the course, including but not limited to *data augmentation, early stopping, and transfer learning*. In order to receive full credit, you are expected to use a model that can classify images into the 10 classes defined in `test.h5` **with an accuracy of at least 60.0%**. An example submission using an untrained model can be seen in the Python cell below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grXEZRsde6lb"},"outputs":[],"source":["# Create a model to save\n","\n","from model import generate_resnet\n","model = generate_resnet(num_classes=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Su6qEMbiOrdG"},"outputs":[],"source":["import os\n","import h5py\n","import torch\n","import numpy as np\n","import shutil\n","from torch.utils.data import DataLoader\n","from dataset import ImageDataset\n","\n","test_h5_path = f\"{env_path}/test.h5\" # Dataset path\n","\n","# Create submission folder\n","os.makedirs(f\"{env_path}/submission\", exist_ok=True)\n","\n","# Load test dataset and dataloader\n","with h5py.File(test_h5_path, \"r\") as f:\n","    images = f[\"images\"][:]\n","test_dataset = ImageDataset(images)\n","test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n","\n","# Predictions to store\n","predictions = list()\n","\n","# Set to evaluation mode\n","model.eval()\n","\n","# Iterate over the test set\n","with torch.no_grad():\n","    for images, _ in test_loader:\n","        # Forward pass\n","        outputs = model(images)\n","        # Get the predictions\n","        _, preds = torch.max(outputs, 1)\n","        predictions.extend(preds.tolist())\n","\n","# Save the outputs (do not change the name)\n","np.savetxt(f\"{env_path}/submission/labels.csv\", predictions, fmt=\"%d\")\n","# Save the handout (do not change the name)\n","shutil.copyfile(f'{env_path}/handout.ipynb', \n","                f'{env_path}/submission/handout.ipynb')"]},{"cell_type":"markdown","metadata":{"id":"6GSUPzxPYG_R"},"source":["You can find the same Python cell above at the end of this notebook."]},{"cell_type":"markdown","metadata":{"id":"ENsGvvPjOrdG"},"source":["## Additional tutorial on deep learning with PyTorch\n","\n","The rest of the notebook consists of a tutorial on some common deep learning operations with PyTorch. This tutorial is completely optional, and not graded. However it introduces different concepts which can be useful for the exercise 5. Thus we highly recommend going through this tutorial. Additionally, we provide different skeleton functions for training deep networks and show how to use them in this tutorial. Feel free to reuse this code for your exercise. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tc4rTF976Zui"},"source":["### Step 1: Define the model\n","For our tutorial, we will be using a toy model `ToyNet` that is defined in the Python cell below. Note that defining a PyTorch network consists of two main steps. Firstly, in the `__init__`  function, we define the different layers that the network has. Secondly, the `forward` function defines how an input to the network is processed by the different layers. We call the process of passing the input through the network layers as 'forward pass' through the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WEpeu0wJOrdH"},"outputs":[],"source":["# Example Toy Model\n","\n","from torch import nn\n","import torch.nn.functional as F\n","\n","class ToyNet(nn.Module):\n","\n","    # model initialization\n","    def __init__(self, input_size=(10,), num_classes=10): \n","        super(ToyNet, self).__init__()\n","        input_size = input_size[0]\n","        self.lin1 = nn.Linear(input_size, 100)\n","        self.lin2 = nn.Linear(100, 100)\n","        self.lin3 = nn.Linear(100, num_classes)\n","\n","    # model forward pass\n","    def forward(self, x): \n","        x = self.lin1(x)\n","        x = F.relu(x)\n","        x = self.lin2(x)\n","        x = F.relu(x)\n","        x = self.lin3(x)\n","        return x\n","\n","model = ToyNet()"]},{"cell_type":"markdown","metadata":{"id":"GPLHZPHoOrdH"},"source":["### Step 2: Summarizing a Model\n","\n","You can learn about a PyTorch neural network `model` using various methods. The standard method for printing a summary of a model on PyTorch is `print(model)`. You can also use an external library such as `torchsummary` to obtain a more detailed summary. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WE6U8-BIOrdI"},"outputs":[],"source":["from torchsummary import summary\n","\n","print(\">>>>> print(model):\")\n","print(model)\n","\n","print(\"\\n\\n>>>>> Torch-Summary:\")\n","summary(model=model, input_size=(10,))"]},{"cell_type":"markdown","metadata":{"id":"5HrlEGuY6JGr"},"source":["The output of the `print` function shows us that the `model` has three sub-modules, namely `lin1`, `lin2`, and `lin3`, each of which is a `Linear` layer.\n","\n","Additionally, the output of `torchsummary` also tells us the size of the model, as well as the number of parameters in the model that are learned, i.e. updated during the backpropagation process. Currently, we see that all the parameters in the model will be trained."]},{"cell_type":"markdown","metadata":{"id":"xXamHe9ZOrdI"},"source":["### Step 3: Extending a model\n","\n","After learning about a given model, you can change the model according to your needs. For example, you can add or remove a layer in the model, or modify an existing layer.  \n","\n","**Task 1:** In the following cell, your task is to extend `model` with a ReLU activation layer at the end. That is, you should construct a new network `model2`, which has the same parameters as `model`, but also has a ReLU layer at the end. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s88PHWEGOrdJ"},"outputs":[],"source":["from torch import nn\n","from evaluation import check_relu_layer\n","from copy import deepcopy\n","\n","model2 = deepcopy(model)\n","\n","#######\n","# Your code here. Extend model2 by adding a ReLU layer at the end\n","\n","#######\n","\n","# Test whether your implementation is correct\n","check_relu_layer(model, model2)"]},{"cell_type":"markdown","metadata":{"id":"9i_023YQ66N0"},"source":["### Step 4: Checking model parameters\n","As you may have seen in the lectures, a layer in a neural network (e.g. a Linear layer) can have learnable parameters. These learnable parameters for a model can be accessed using the `parameters()` function of a neural network module. \n","\n","For instance, we can view the number of parameters in the `lin1` layer as follows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPL7Sk917DX9"},"outputs":[],"source":["# Get all the parameters\n","params_list = list(model.lin1.parameters())\n","\n","print(f'Lin1 layer has {len(params_list)} parameter blocks')\n","print(f'The shape of the first paramter block is {params_list[0].shape}')\n","print(f'The shape of the second paramter block is {params_list[1].shape}')"]},{"cell_type":"markdown","metadata":{"id":"gWQDt1Si7HG9"},"source":["**Questions:** What do these two parameter blocks correspond to? Can you figure out why the shape of the first block is `(100, 10)`, while that of second is only `(100, )`?\n","\n","Additionally, you can get all the parameters in the `ToyNet` by calling the `parameters()` function on the top level module."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tdh4kmkq7I8A"},"outputs":[],"source":["all_params = list(model.parameters())\n","print(f'ToyNet has {len(all_params)} parameter blocks')"]},{"cell_type":"markdown","metadata":{"id":"mvYx4rZy7Os8"},"source":["You can iterate through these parameter blocks in the 'pythonic' way as follows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kb0X08pY7OBY"},"outputs":[],"source":["for param in model.parameters():\n","    print(f'Shape of parameter block is {param.shape}')"]},{"cell_type":"markdown","metadata":{"id":"4tfi4RMC7XAJ"},"source":["In addition to the `shape` attribute, a parameter block has many more interesting properties. In particular, one crucial attribute related to the training of the network parameters is the `requires_grad` flag, which tells `PyTorch` whether it should compute gradients for this parameter block. You may be aware that neural networks are trained using the backpropagation algorithm, in which we iteratively update each of the network parameters using the computed gradients. \n","\n","We can check whether our parameter blocks require gradients or not as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgXkNsG77Z-K"},"outputs":[],"source":["for i, param in enumerate(model.parameters()):\n","    print(f'Parameter block {i} requires_grad is: {param.requires_grad}')"]},{"cell_type":"markdown","metadata":{"id":"MlCVALLP7ger"},"source":["As we can see, by default, all parameter blocks in a network require gradients. That is, all the parameters in the neural network are updated when training the network. However, you can control this property by manually setting the `requires_grad` flag to `False`, to 'freeze' a particular layer during training. This will allow you to keep certain parameters in a network fixed, while learning the other paramters.\n","\n","**Question:** When would you desire such a property? Can you think of a case where you want to keep certain network parameters fixed, i.e. not learn them?"]},{"cell_type":"markdown","metadata":{"id":"yo2lRgsT7nFM"},"source":["**Task 2:** Your task next is to freeze the first and third layer of the `model`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyhBdSGNOrdJ"},"outputs":[],"source":["from evaluation import check_freezing\n","\n","#################\n","# Your code here. You need to freeze the first and the third layers \n","# (lin1 and lin3). That is, the requires_grad attribute should be False for \n","# the paramters in these layers\n","\n","#################\n","\n","check_freezing(model)"]},{"cell_type":"markdown","metadata":{"id":"vA-isNgEOrdK"},"source":["### Step 5: Learning the model parameters\n","\n","In the network training process, our aim is to learn a set of parameters which minimize our training loss. This is achieved by using some form of gradient-based update algorithm, e.g. stochastic gradient descent. Fortunately, PyTorch can calculate the gradients of network parameters with respect to the training loss, using its `autograd` mechanism. A simple illustration of this is provided below.\n","\n","We define two variables $a$ and $b$, set to 2 and 3 respectively. We define our 'loss' as $(a-b)^2$. Our goal is to update $a$ such that we can minimize the loss. We can achieve this by performing gradient descent. To do this, we want to first compute the gradient $\\frac{\\text{d}loss}{\\text{d}a}$. For our simple problem, we can manually calculate the gradient, which we know is $2(a-b)$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sjLMLPnh72Mn"},"outputs":[],"source":["# Define the tensors a and b. For tensor a, we set requires_grad to True, since\n","# we want to calculate its gradients\n","a = torch.tensor([2.0], requires_grad=True)\n","b = torch.tensor([3.0])\n","\n","# Compute loss\n","loss = (a-b)**2\n","\n","# Compute the gradients for each input. \n","# This is achieved by calling the backward function.\n","loss.backward()\n","\n","print(f'Gradient w.r.t. a is {a.grad}')\n","print(f'Gradient w.r.t. b is {b.grad}')"]},{"cell_type":"markdown","metadata":{"id":"2MVsASaO75Xp"},"source":["We can see that the gradient w.r.t. $a$ is -2, which is equal to $2(a-b) = 2(2 - 3) = -2$. Thus, we see that PyTorch can compute the gradients automatically. While in our simple case, we could manually obtain an expression for the gradients as $2(a-b)$, this is not feasible to compute when dealing with deep neural networks, consisting of many complex operations. PyTorch's `autograd` functionality allows us to automatically compute the gradients even in such cases. You can refer to https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html for more information about `autograd` in PyTorch.\n","\n","**Question:** Why was gradient w.r.t. $b$ set to `None` in our example?\n","\n","Once we compute the gradients for each parameter, the next step is to update the parameter values. As you may have already seen in exercise 4, this is done using the [`optimizer` module in PyTorch](https://pytorch.org/docs/stable/optim.html). One can use many different types of optimizers, e.g. SGD, Adam, etc. In our example, we will use the SGD optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JW-K5Xfe78uI"},"outputs":[],"source":["import torch.optim as optim\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"cEcul3Fn79Qa"},"source":["The first input argument to `optim.SGD` is `model.parameters()`. Why is that? Basically we want to tell the optimizer which parameter blocks in the model we want to update. By sending `model.parameters()` as input, we are telling the optimizer that it can update all the parameter blocks. However, note that the optimizer can only update the paramter blocks for which gradients are computed. So for instance, if the `requires_grad` flag for certain layers are set to `False`, the optimizer cannot update those layer parameters. \n","\n","**Task:** Construct an optimizer which will only update the parameters of the last linear layer, i.e. `lin3`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOVmyQsK8DiL"},"outputs":[],"source":["optimizer = optim.SGD(\"TODO: Pass the correct parameters here\", lr=0.01, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"bDQEbVgt8Hwd"},"source":["### Step 6: Fine-tuning a network\n","\n","Until now, we have only considered whether to train a full network, or 'freeze' certain layers in the network while learning others. However, in certain cases, we may wish to slightly adapt certain layers, while learning others from scratch. Such a behaviour is controlled using the learning rate. Instead of using a fixed learning rate for all the parameters in the network, we could use different learning rates for different parameters. This will allow us to control how much the network paramters may change, compared to their initial value. \n","\n","We can obtain this behaviour as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WAaR4W78Lj3"},"outputs":[],"source":["import torch.optim as optim\n","optimizer = optim.SGD([\n","                          {'params': model.lin1.parameters(), 'lr': 0.02},\n","                          {'params': model.lin2.parameters(), 'lr': 0.05},\n","                          {'params': model.lin3.parameters(), 'lr': 0.1},\n","                       ], lr=0.01, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"QKH0n5S08QFb"},"source":["Observe that instead of passing `model.parameters()` as the first arugment, we are passing a `List` of dictionaries. Each dictionary contains a set of parameters, as well as the learning rate to use for the particular set of parameters. In this example, the optimizer will use a learning rate of $0.02$ for layer 1 (`lin1`) parameters, $0.05$ for layer 2 (`lin2`) parameters and so on."]},{"cell_type":"markdown","metadata":{"id":"9N9rOa1jHxMc"},"source":["### Step 7: Saving a network\n","Once we train a neural network, we may want to save the learned model for later use. In order to do so, we save the learned parameters, which we can easily reload later. The funtion `state_dict()` provides a dictionary containing each of the layer name in the network, and the corresponding parameters. Basically, for each parameter block in the network, we obtain the name of the parameter, and its weights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dufOzrTUH7BU"},"outputs":[],"source":["state_dict = model.state_dict()\n","\n","print(f'The model has following parameter blocks')\n","print(list(state_dict.keys()))\n","print('The shape of lin1.weight parameter is ', \n","      state_dict[\"lin1.weight\"].shape)"]},{"cell_type":"markdown","metadata":{"id":"OD6ckzEBIMEc"},"source":["Once we have the state dict, we can easily save it to the disk using `torch.save`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vacDiXZ7IM9w"},"outputs":[],"source":["# Save model to the given path\n","torch.save(model.state_dict(), f\"{env_path}/ckpt/toy_model.pt\")"]},{"cell_type":"markdown","metadata":{"id":"i6NudjV1IRSj"},"source":["Later, you can load a saved network weights and assign to your model. For example you can construct a new instance of `ToyNet`, and assign the saved parameters to it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEoQkKs7IU5B"},"outputs":[],"source":["# Create a new model\n","model_new = ToyNet()\n","\n","# Load previously saved weight\n","old_weights = torch.load(f\"{env_path}/ckpt/toy_model.pt\")\n","\n","# Set the old weights to the new model\n","model_new.load_state_dict(old_weights)\n"]},{"cell_type":"markdown","metadata":{"id":"2JSrzXvdIUJ6"},"source":["Now you know how to adapt a given model, train or finetune only a few layers in the network, and save and load a learned model :) \n","\n","This should be sufficient to tackle Exercise 5. We further provide a small toy setup below where you can play around with the concepts you have learned, without having to wait for long training times. Additionally we provide a number of useful functions such as `train_model`, `evaluate_model`, and `plot_training_log` to train, evaluate your model, and visualize the training process, respectively. Feel free to reuse these functions to train your own networks."]},{"cell_type":"markdown","metadata":{"id":"kkeJ_U9l8h5t"},"source":["### Step 8: Playing with a Toy problem\n","\n","For the next part of the tutorial, we train the toy model on a toy dataset. First we construct the toy dataset, and corresponding dataloaders."]},{"cell_type":"markdown","metadata":{"id":"Hq0k364uRwVj"},"source":["*Information regarding the toy dataset:*\n"," \n","The toy dataset is constructed by generating random vectors $\\{\\mathbf{x}_i\\}_{i=1}^{\\text{num_samples}}$ of size `data_size` (default `(10,)`) as inputs according to normal distribution. For calculation of outputs, first a basic polynomial is introduced\n","\n","$$\n","\\bar{y}_i = \\sum_j x_{ij}^2 - 5x_{ij} + 3\n","$$\n","\n","with some additive Gaussian noise\n","\n","$$\n","y_i = \\bar{y}_i + \\zeta \\ , \\ \\ \\zeta \\sim N(0, \\text{noise_std}^2).\n","$$\n","\n","The classes are defined by classifying outputs into uniformly separated bins\n","\n","$$\n","c_i = \\{ c: l_c \\leq y_i < u_c \\}\n","$$\n","\n","where $u_{c} = l_{c+1}$ and\n","\n","$$\n","l_c = y_{min} + c \\cdot \\frac{y_{max} - y_{min} + \\epsilon}{\\text{num_classes}}, \\ \\ \\epsilon = \\frac{y_{max} - y_{min}}{1000}.\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUqeEfSZOrdK"},"outputs":[],"source":["# Toy Dataset and Dataloaders\n","\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","\n","class ToyDataset(Dataset):\n","\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","        self.unique_labels = list(set(labels))\n","        self.num_classes = len(self.unique_labels)\n","        self.data_size = data.shape[1:]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return (torch.tensor(self.data[idx], dtype=torch.float32), \n","                self.labels[idx])\n","\n","def get_toydataset_randomly(num_samples=500, num_classes=10, data_size=(10,), \n","                            tvt_ratio=(0.7, 0.1, 0.2), noise_std=0.5):\n","    \n","    tvt_ratio = np.array(tvt_ratio)\n","    tvt_ratio = tvt_ratio / tvt_ratio.sum()\n","    \n","    data = np.random.rand(num_samples, *data_size)\n","    x = data**2 - 5*data + 3\n","    while len(x.shape) > 1:\n","        x = x.sum(axis=1)\n","    eps = (x.max() - x.min()) / 1000\n","    bins = np.linspace(x.min(), x.max()+eps, num_classes)\n","    labels = np.digitize(x, bins) - 1\n","    data = data + np.random.rand(*data.shape) * noise_std\n","\n","    train_size = int(num_samples * tvt_ratio[0])\n","    val_size = int(num_samples * tvt_ratio[1])\n","    test_size = num_samples - train_size - val_size\n","\n","    train_dataset = ToyDataset(data[:train_size], labels[:train_size])\n","    val_dataset = ToyDataset(data[train_size:train_size+val_size], \n","                             labels[train_size:train_size+val_size])\n","    test_dataset = ToyDataset(data[train_size+val_size:], \n","                              labels[train_size+val_size:])\n","    return train_dataset, val_dataset, test_dataset\n","\n","def get_loaders_from_datasets(train_dataset, val_dataset, test_dataset, \n","                              batch_size=50):\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n","                              shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n","                            shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n","                             shuffle=False)\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"markdown","metadata":{"id":"BycCqSILIpKr"},"source":["Here is the final training block, where we set the training parameters and train models. Feel free to change different parameters / optimizers / learning rates etc and see the impact on training. We provide documentation for each of the functions in the corresponding files. Do check them out to see the different features available to you. Additionally, you can encouraged to look at the function implementations. Good luck!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCFDYkhuOrdK"},"outputs":[],"source":["# Training\n","\n","import os\n","import torch\n","from torch import nn, optim\n","from torchsummary import summary\n","\n","from training import train_model\n","\n","from evaluation import evaluate_model\n","from utils import plot_training_log, seed_everything\n","\n","seed = 1234567 # Give a random seed\n","seed_everything(seed)\n","\n","save_path = f\"{env_path}/ckpt/best_toy_model.pt\" # Path to save the model to\n","\n","# Random toy dataset parameters\n","\"\"\"\n","You can change these parameters to see how they affect the training\n","\"\"\"\n","num_samples = 1000 # Number of samples in the dataset\n","data_size = (10,) # Input size of the dataset\n","num_classes = 10 # Number of classes in the dataset\n","tvt_ratio = (0.7, 0.1, 0.2) # Train, validation, test ratio\n","\n","# Training parameters\n","\"\"\"\n","You can change these parameters to see how they affect the training\n","\"\"\"\n","batch_size = 50 # Batch size for training\n","num_epochs = 200 # Number of epochs to train for\n","learning_rate = 0.001 # Learning rate for the optimizer\n","weight_decay = 0.0 # Weight decay for the optimizer\n","best_of = \"loss\" # Model to save based on \"loss\" or \"accuracy\" on validation set\n","\n","device = \"cpu\" # Device to train on \n","\n","# Take the datasets from h5 file\n","train_dataset, val_dataset, test_dataset = \\\n","    get_toydataset_randomly(num_samples=num_samples, num_classes=num_classes, \n","                            data_size=data_size, tvt_ratio=tvt_ratio)\n","\n","# Take the loaders from the datasets\n","train_loader, val_loader, test_loader = \\\n","    get_loaders_from_datasets(train_dataset, val_dataset, \n","                              test_dataset, batch_size)\n","\n","# Create the model and summarize\n","num_classes = train_dataset.num_classes\n","input_size = train_dataset.data_size\n","model = ToyNet(input_size=input_size, num_classes=num_classes)\n","summary(model=model, input_size=input_size)\n","\n","# Send model to device\n","model.to(device)\n","\n","# Set Criterion (loss function) and Optimizer\n","criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n","optimizer = optim.SGD(params=model.parameters(), lr=learning_rate, \n","                       weight_decay=weight_decay)\n","\n","# Train the model\n","training_log = train_model(model, train_loader, val_loader, \n","                           criterion=criterion, optimizer=optimizer,\n","                           best_of=best_of, num_epochs=num_epochs, \n","                           device=device, save_path=save_path)\n","\n","# Load the best model \n","model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n","\n","# Evaluate the model\n","test_accuracy = evaluate_model(model, test_loader, device=device)\n","print(f\"Test accuracy: {test_accuracy:.4f}\")\n","\n","# Plot the training log\n","plot_training_log(training_log, test_accuracy, show_baseline=True)"]},{"cell_type":"markdown","metadata":{"id":"9bThsKaQEDzh"},"source":["## Your Solution\n","\n","You can write your own implementation here. You can change the custom functions given according to your needs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOLPuce0A5gj"},"outputs":[],"source":["# You can implement your model here\n","\n","# Standard Libraries\n","import torch\n","from torch import nn\n","from torchsummary import summary\n","import numpy as np\n","\n","# Custom Functions\n","from utils import seed_everything, plot_training_log\n","from model import generate_resnet\n","from dataset import get_datasets_from_h5, get_loaders_from_datasets\n","from training import train_model\n","from evaluation import evaluate_model\n","\n","seed = 1234567 # Give a random seed\n","seed_everything(seed)\n","\n","h5_path = f\"{env_path}/training.h5\" # Training dataset path\n","save_path = f\"{env_path}/ckpt/best_model.pt\" # Path to save the model to\n","pre_pt = f\"{env_path}/resnet4five.pt\" # Path to pretrained model\n"]},{"cell_type":"markdown","metadata":{"id":"1LI94WFCbRtQ"},"source":["## Generating the final submission\n","\n","When you are happy with your network, you can run the next cell to generate your network predictions on the final test set, which will be stored in the submission directory on your Google Drive.\n","Download the submission folder (without renaming) as a zip, and upload it to the evaluation server at https://codalab.lisn.upsaclay.fr/competitions/9001 to obtain the scores on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5cu-b_AB8Rp"},"outputs":[],"source":["import os\n","import h5py\n","import torch\n","import numpy as np\n","import shutil\n","from torch.utils.data import DataLoader\n","from dataset import ImageDataset\n","\n","test_h5_path = f\"{env_path}/test.h5\" # Dataset path\n","\n","# Create submission folder\n","os.makedirs(f\"{env_path}/submission\", exist_ok=True)\n","\n","# Load test dataset and dataloader\n","with h5py.File(test_h5_path, \"r\") as f:\n","    images = f[\"images\"][:]\n","test_dataset = ImageDataset(images)\n","test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n","\n","# Predictions to store\n","predictions = list()\n","\n","# Set to evaluation mode\n","model.eval()\n","\n","# Iterate over the test set\n","with torch.no_grad():\n","    for images, _ in test_loader:\n","        # Forward pass\n","        outputs = model(images)\n","        # Get the predictions\n","        _, preds = torch.max(outputs, 1)\n","        predictions.extend(preds.tolist())\n","\n","# Save the outputs (do not change the name)\n","np.savetxt(f\"{env_path}/submission/labels.csv\", predictions, fmt=\"%d\")\n","# Save the handout (do not change the name)\n","shutil.copyfile(f'{env_path}/handout.ipynb', \n","                f'{env_path}/submission/handout.ipynb')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lR_r0ljPv6oD"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"d349895c10127427517933488e6793b5c193c1719f50c3e38636a42f2083d09c"}}},"nbformat":4,"nbformat_minor":0}
