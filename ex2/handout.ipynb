{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+Lc8GSHiNUiWp+P2FMJfv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercise 2: Interactive Segmentation\n","\n","**Deadline: 23 December 2022, 11:59 PM**            \n","\n","**Covered Topics: Lecture 5**\n","\n","Your tic-tac-toe championship was a major success and everyone is waiting for the next event from you. Meanwhile, some curious eyes have also noticed the impressive compression algorithm you developed. Among them is a group of budding entrepreneurs who are working on a noble mission: to empower everyone to make their own *Cat Memes*. Specifically, they are developing an app where you can take a photo of your cute cat, segment it out, and paste it on any  background to design your own meme. Crucially, the users only have to mark a bounding box around the cat, and the app will automatically segment it. Since performing accurate segmentation is very challenging, the app also uses a second auxiliary image obtained using other sensors in the camera as input. As none of the founders are Computer Vision engineers, they have approached you to develop the segmentation algorithm for the app. An overview of the desired pipeline is shown in Figure.\n","\n","\n","![](https://drive.google.com/uc?export=view&id=1C_UxSb8zKf5BU06TUg3YJx4uIdargySf \"Title\")\n","\n","**Details about the setup** \n","* For each test sample, the algorithm is provided a triplet consisting of the RGB image, the auxiliary image, and the bounding box for the cat. We denote this triplet as a *sample*. \n","* The bounding box for the cat is provided as a grayscale image, where the regions inside the box are set to 255 (white), while the regions outside the box are set to 0 (black). It is guaranteed that the cat lies fully inside the bounding box.\n","* Both the RGB image and the Auxiliary images are discrete images containing 3 channels. Each pixel in these images is an integer which can take values between [0, 255]\n","* For each sample, the RGB image and the Auxiliary image, and the bounding box image all have the same height and width. However, note that two RGB images from two different samples may have different sizes.\n","\n","\n","Given an input sample, your algorithm should output a single channel segmentation mask, of the same height and width as the input images. The output mask should be a NumPy array of data type `uint8`, with values 255 for the foreground (cat) regions, and value 0 for the background regions. In order to design your segmentation algorithm, we provide a validation dataset containing 10 samples, along with the ground truth segmentation mask for each of these samples.\n","\n","**Evaluation Criteria**\n","\n","Your algorithm will be evaluated using the Intersection-over-Union (IoU) metric. Given the ground truth mask and the predicted mask for a sample, the metric computes the i) intersection of the two masks, i.e. number of pixels for which both the masks are set to foreground (value 255), and ii) the union of the two masks, i.e. number of pixels for which either one of the masks is set to foreground (value 255). The IoU metric is then obtained as the ratio \n","\n","$$\n","\\text{IoU} = \\frac{\\text{Intersection of ground truth and predicted masks}}{\\text{Union of ground truth and predicted masks}} \n","$$\n","\n","Please refer to the evaluation script included in this notebook (`evaluation.py`) for more details about IoU metric. The final EvaluationScore is obtained as the mean IoU over all test samples. Since the segmentation algorithm can be stochastic, i.e. output different masks at different times, we run the algorithm on the test dataset 5 times, and compute the mean EvaluationScore over these 5 runs. \n","\n","\n","**Passing requirement**\n","\n","Your algorithm will be evaluated using an online evaluation server on a hidden test set. In order to pass the exercise, you need to obtain an EvaluationScore of **greater than $0.630$** on the test set. Additionally, your segmentation algorithm should be reasonably fast, that is, segment each sample in less than 5 seconds. This is because the evaluation server will time out if your algorithm is too slow. The ranking on the leaderboard is obtained using only the EvaluationScore.\n","\n","Follow the steps in the rest of the notebook to generate the submission. The evaluation server for the exercise is at https://codalab.lisn.upsaclay.fr/competitions/8068."],"metadata":{"id":"dnLsCjLDMiCO"}},{"cell_type":"markdown","source":["## Initialize the environment and load data\n","Import the necessary libraries. Note that you are **NOT** allowed to use any additional libraries"],"metadata":{"id":"BTx8Wss3eD0j"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9eaRYAf_iWs"},"outputs":[],"source":["# These two lines ensure that we always import the latest version of a package, in case it has been modified.\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","import cv2\n","import os\n","import numpy as np\n","import random\n","import shutil\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","\n","# Install and import PyMaxFlow. This library can be used to perform min-cut\n","!pip install PyMaxflow\n","import maxflow"]},{"cell_type":"markdown","source":["**TODO:** Set the path in Google drive where you uploaded the handout, e.g. My Drive/iacv/ex2\n","\n"],"metadata":{"id":"L_TTjEHrMfIK"}},{"cell_type":"code","source":["iacv_path = 'SET_THIS_PATH' # TODO set this\n","\n","env_path = f'/content/drive/{iacv_path}'\n","# Add the handout folder to python paths\n","if env_path not in sys.path:\n","    sys.path.append(env_path)\n","\n","import evaluation"],"metadata":{"id":"GTVU1pMT_pMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper functions to load and display images. You do not need to modify these functions."],"metadata":{"id":"I1zPcYLMeMEm"}},{"cell_type":"code","source":["def load_image(im_path):\n","    im = cv2.imread(im_path)\n","    \n","    # OpenCV loads images in BGR format, that is first channel in the image is blue, second is green, and third is red.\n","    # matplotlib (which we will use to display images) on the image hand expects images in RGB format. Hence we perform a color conversion\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)   \n","    return im\n","\n","\n","def load_sample(sample_path):\n","    im_rgb = load_image(sample_path + '/im_rgb.jpg')\n","    im_aux = load_image(sample_path + '/im_aux.jpg')\n","    im_box = cv2.imread(sample_path + '/box.jpg', cv2.IMREAD_GRAYSCALE)\n","\n","    mask = cv2.imread(sample_path + '/mask.jpg', cv2.IMREAD_GRAYSCALE)\n","       \n","    return im_rgb, im_aux, im_box, mask\n","\n","\n","def show_image(im, title=None):\n","    plt.imshow(im)\n","    plt.title(title)\n","    plt.show()\n","\n","\n","def show_sample(im_rgb, im_aux, im_box, pred_mask=None, gt_mask=None):\n","    num_images = 3 + (pred_mask is not None) + (gt_mask is not None)\n","\n","    fig, ax = plt.subplots(1, num_images, figsize=(20, 20))\n","\n","    ax[0].imshow(im_rgb)\n","    ax[0].set_title('RGB Image')\n","\n","    ax[1].imshow(im_aux)\n","    ax[1].set_title('Aux Image')\n","    \n","    ax[2].imshow(im_box)\n","    ax[2].set_title('Box')\n","\n","    idx = 3\n","    if gt_mask is not None:\n","        ax[idx].imshow(gt_mask)\n","        ax[idx].set_title('GT Mask')\n","        idx += 1 \n","\n","    if pred_mask is not None:\n","        ax[idx].imshow(pred_mask)\n","        ax[idx].set_title('Pred Mask')\n","    plt.show()"],"metadata":{"id":"9-jGYXudAG5o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize a few validation samples, along with ground truth to get an idea of how the images look. You can run this cell multiple times to visualize different images."],"metadata":{"id":"n2TR9DG4qeWM"}},{"cell_type":"code","source":["sample_id = random.randint(0, 9)\n","im_rgb, im_aux, im_box, mask = load_sample(f'{env_path}/val/{sample_id:02d}')\n","show_sample(im_rgb, im_aux, im_box, gt_mask=mask)"],"metadata":{"id":"z6MpuaS71jiF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implement your solution\n","\n","**TODO:** You are provided with a simple implementation of the `ImageSegmenter` class (image_segmenter.py). The `ImageSegmenter` class is responsible to generate a segmentation mask, given the RGB image, Aux image, and the box containing the cat. Modify this class to include your algorithm. The `image_segmenter.py` file also provides a simple fuction to perform min cut using PyMaxFlow library (http://pmneila.github.io/PyMaxflow/), which you can **optionally** use. **Note:** You are not allowed to use any external packages except the ones already imported in `image_segmenter.py`. Otherwise your submission will crash on the Evaluation server.\n","\n","**Important:** The next cells demonstrate how the `ImageSegmenter` class will be used. Have a look at them before implementing your approach.\n"],"metadata":{"id":"J0N6d1dTtdVS"}},{"cell_type":"markdown","source":["## Test your solution on validation set\n","\n","Test your algorithm on some validation samples and visualize the output. \n","\n","**Important:** Don't forget to import the `image_segmenter` every time you modify the `image_segmenter.py` file, otherwise your latest changes won't be loaded."],"metadata":{"id":"in9FC-EhufXa"}},{"cell_type":"code","source":["# Import the image_segmenter class everytime you modify image_segmenter.py file. \n","# Otherwise your changes won't be loaded\n","import image_segmenter as image_segmenter\n","\n","# Initialize the segmenter object\n","segmenter = image_segmenter.ImageSegmenter()\n","\n","# Load validation sample\n","im_rgb, im_aux, im_box, gt_mask = load_sample(f'{env_path}/val/00')\n","\n","# Run your segmentation algorithm\n","pred_mask = segmenter.segment_image(im_rgb, im_aux, im_box)\n","\n","# Visualize your prediction\n","show_sample(im_rgb, im_aux, im_box, gt_mask=gt_mask, pred_mask=pred_mask)\n","\n","iou_score = evaluation.calculate_iou(gt_mask, pred_mask)\n","print(f'IoU score is: {iou_score:0.3f}')"],"metadata":{"id":"1565TAgUh-ie"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once your are happy with your implementation, you can test on the full validation set to obtain the evaluation score. **Important:** Ensure that you can execute the next cell without any errors to compute the evaluation score. \n","\n","Set `display_results` variable to `True` if you want to visualize your predictions."],"metadata":{"id":"_avHdNI123Hz"}},{"cell_type":"code","source":["import image_segmenter as image_segmenter\n","import time\n","\n","display_results = False\n","\n","# Initialize the segmenter object\n","segmenter = image_segmenter.ImageSegmenter()\n","\n","iou_score_all = []\n","time_all = []\n","for idx in range(10):\n","    # Load validation sample\n","    im_rgb, im_aux, im_box, gt_mask = load_sample(f'{env_path}/val/{idx:02d}')\n","\n","    # Run your segmentation algorithm\n","    t1 = time.time()\n","    pred_mask = segmenter.segment_image(im_rgb, im_aux, im_box)\n","    t2 = time.time()\n","    \n","    iou_score = evaluation.calculate_iou(gt_mask, pred_mask)\n","    iou_score_all.append(iou_score)\n","    time_all.append(t2 - t1)\n","    if display_results:\n","        # Visualize your prediction\n","        show_sample(im_rgb, im_aux, im_box, gt_mask=gt_mask, pred_mask=pred_mask)\n","        print(f'IoU score is: {iou_score:0.3f}')\n","    \n","\n","mean_iou = sum(iou_score_all) / len(iou_score_all)\n","print(f'Mean IoU score is: {mean_iou:0.3f}')\n","\n","mean_time = sum(time_all) / len(time_all)\n","print(f'Mean segmentation time per image is: {mean_time:0.3f} seconds')"],"metadata":{"id":"tk5cp1ix3BwL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generate the final submission on the test set\n","\n","After finishing your implementation, you can run the next cell to generate the results, which will be stored in the submission directory on your Google Drive. This cell saves your implementation of the `image_segmenter.py` to the submission directory. Download the submission folder (**without renaming**) as a zip, and upload it to the evaluation server at https://codalab.lisn.upsaclay.fr/competitions/8068 to obtain the scores on the test set. \n"],"metadata":{"id":"7r0OT0aVvkWi"}},{"cell_type":"code","source":["out_dir = f'{env_path}/submission'\n","os.makedirs(out_dir, exist_ok=True)\n","shutil.copyfile(f'{env_path}/image_segmenter.py', f'{out_dir}/image_segmenter.py')"],"metadata":{"id":"XxncC929jV4t"},"execution_count":null,"outputs":[]}]}